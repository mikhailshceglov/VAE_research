# Lab3: Variational Autoencoder on CIFAR-10

**Последнее обновление:** 25 апреля 2025 г.

## Обзор проекта

В работе реализуется вариационный автоэнкодер (VAE) для датасета **CIFAR-10**. После обучения модели генерируются синтетические изображения, на которых обучается сверточный классификатор.

**Поставленные задачи**
1. Обучить VAE с нуля на CIFAR-10.
2. Для каждого класса вычислить средний латентный вектор.
3. Добавив к среднему вектору случайный шум, сгенерировать 5 000 новых изображений на класс.
4. Обучить классификатор на синтетических данных и проверить его на реальных изображениях CIFAR-10.
5. Сравнить полученную точность с результатами предыдущей лабораторной.

---

## Требования

* Python ≥ 3.8  
* PyTorch ≥ 1.10  
* torchvision  
* TensorFlow ≥ 2.6  
* tqdm  
* matplotlib  
* numpy  
* scikit-learn

Установить зависимости можно командой:

```bash
pip install -r requirements.txt
```

---

## Установка и запуск окружения

```bash
# Клонировать репозиторий
git clone <URL-репозитория>.git
cd lab3

# Создать и активировать виртуальное окружение (Linux / macOS)
python3 -m venv .venv
source .venv/bin/activate

# Для Windows
# python -m venv .venv
# .venv\Scripts\activate

# Установить зависимости
pip install --upgrade pip
pip install -r requirements.txt
```

---

## Структура репозитория

```text
lab3/
├── ai3.txt               # Условие лабораторной
├── requirements.txt      # Зависимости проекта
├── data.py               # Загрузка CIFAR-10
├── vae.py                # Архитектура VAE
├── train_vae.py          # Скрипт обучения VAE
├── generate_data.py      # Генерация синтетических изображений
├── train_classifier.py   # Обучение классификатора на синтетике
└── visualize_recon.py    # Визуализация (recon, PCA, кривые)
```

---

## Запуск скриптов

> Все команды выполняются из корня каталога `lab3` в активированном виртуальном окружении.

### 1. Обучение VAE

```bash
python train_vae.py
```

*Сохраняемые файлы*:
* `vae_model.pt` — веса обученного VAE.
* В окне matplotlib отображаются кривые Recon MSE и KL-дивергенции.

### 2. Генерация синтетических данных

```bash
python generate_data.py
```

*Требуется*: `vae_model.pt`

*Сохраняемые файлы*:
* `synthetic_images.pt`
* `synthetic_labels.pt`

### 3. Обучение классификатора

```bash
python train_classifier.py
```

*Сохраняемые файлы*:
* `classifier_on_synthetic.h5` — веса модели Keras.
* `history.npy` — история обучения (loss, accuracy).

### 4. Визуализация результатов

```bash
python visualize_recon.py
```

*Сохраняемые изображения*:
* `training_curves.png` — кривые обучения VAE.
* `reconstructions.png` — оригиналы и реконструкции (8 пар).
* `latent_mu_pca.png`, `latent_sigma_pca.png` — 2-D PCA латентных параметров µ и σ.

---

## Файлы и артефакты

Следующие файлы генерируются во время работы скриптов и не должны попадать в Git:

* `*.pt`, `*.pth`, `*.h5` — веса моделей.
* `*.npy`, `*.png` — логи и графики.
* `data/` — загружаемый автоматически архив CIFAR-10.

---

## Параметры обучения VAE

| Параметр           | Значение | Описание                                  |
|--------------------|----------|-------------------------------------------|
| `latent_dim`       | 256      | Размер латентного пространства            |
| `batch_size`       | 32       | Размер мини-батча                         |
| `epochs`           | 20       | Число эпох обучения                       |
| `learning_rate`    | 1e-4     | Скорость обучения Adam                    |
| `β` (KL-annealing) | 0 → 1 за 100 эпох | Плавное включение KL-регуляризатора |

---

## Архитектура VAE (кратко)

```text
Энкодер
-------
Input   : 3 × 32 × 32
Conv2d  : 3  →  64, k=4, s=2, p=1  → BN → ReLU   # 64 × 16 × 16
Conv2d  : 64 → 128, k=4, s=2, p=1  → BN → ReLU   # 128 × 8 × 8
Conv2d  : 128→ 256, k=4, s=2, p=1  → BN → ReLU   # 256 × 4 × 4
Conv2d  : 256→ 512, k=4, s=2, p=1  → BN → ReLU   # 512 × 2 × 2
Flatten → fc_mu & fc_logvar (512*2*2 → 256)

Декодер
-------
Linear  : 256 → 512*2*2 → reshape 512 × 2 × 2
ConvTr  : 512→256, k=4, s=2, p=1   → BN → ReLU   # 256 × 4 × 4
ConvTr  : 256→128, k=4, s=2, p=1   → BN → ReLU   # 128 × 8 × 8
ConvTr  : 128→ 64, k=4, s=2, p=1   → BN → ReLU   # 64  × 16 × 16
ConvTr  : 64 →  3, k=4, s=2, p=1   → Sigmoid    # 3   × 32 × 32
```

---

## Результаты

* **Recon MSE** снизилось c ≈ 0.085 до ≈ 0.022 за 20 эпох.
* **KL-дивергенция** стабилизировалась около 45.
* **PCA латентных средних** показала отчётливое разделение классов.
* **Синтетика**: 50 000 изображений (5 000 × 10 классов) с удовлетворительным качеством.
* **Классификатор** достиг точности ≈ 72 % на реальном CIFAR-10 (против ≈ 70 % без аугментации).

---

## Перспективы дальнейшей работы

* Комбинация VAE и GAN (VAE-GAN) для повышения чёткости изображений.
* Добавление residual-блоков и attention-механизмов.
* Эксперименты с размерностью латента и расписанием β.
* Применение метода к более сложным датасетам (CIFAR-100, ImageNet).

